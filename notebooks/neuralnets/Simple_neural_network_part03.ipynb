{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Neural network\n",
    "## Part 3: Hidden layer\n",
    "\n",
    "This tutorial is part 3 of the previous tutorials on neural networks (TODO: url). While the previous tutorials described very simple single layer regression and classification models, this tutorial will describe a 2-class classification neural network with 1 input dimension, and a non-linear hidden layer with 2 dimensions. While we didn't add the bias parameters to the previous 2 models, we will add them to this model. The network of this model is shown in the following figure:\n",
    "\n",
    "![Image of the logistic model](https://dl.dropboxusercontent.com/u/8938051/Blog_images/SimpleANN03.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import numpy as np # Matrix and vector computation package\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "# Allow matplotlib to plot inside this notebook\n",
    "%matplotlib inline\n",
    "# Set the seed of the numpy random number generator so that the tutorial is reproducable\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the dataset \n",
    "\n",
    "In this example the target classes $t$ will be generated from 2 class distributions: blue ($t=1$) and red ($t=0$). Where the red class is a [multimodal distribution](http://en.wikipedia.org/wiki/Multimodal_distribution) that surrounds the distribution of the blue class. This results in a 1D dataset that is not linearly seperable. The model from part 2 won't be able to classify both classes correctly since it can learn only linear seperators. By adding a hidden layer the model will be able to train a non-linear seperator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define and generate the samples\n",
    "nb_of_samples_per_class = 20  # The number of sample in each class\n",
    "blue_mean = [0]  # The mean of the blue class\n",
    "red_left_mean = [-2]  # The mean of the red class\n",
    "red_right_mean = [2]  # The mean of the red class\n",
    "\n",
    "std_dev = 0.5  # standard deviation of both classes\n",
    "# Generate samples from both classes\n",
    "x_blue = np.random.randn(nb_of_samples_per_class, 1) * std_dev + blue_mean\n",
    "x_red_left = np.random.randn(nb_of_samples_per_class/2, 1) * std_dev + red_left_mean\n",
    "x_red_right = np.random.randn(nb_of_samples_per_class/2, 1) * std_dev + red_right_mean\n",
    "\n",
    "\n",
    "# Merge samples in set of input variables x, and corresponding set of\n",
    "# output variables t\n",
    "x = np.vstack((x_blue, x_red_left, x_red_right))\n",
    "# print x\n",
    "t = np.vstack((np.ones((x_blue.shape[0],1)), \n",
    "               np.zeros((x_red_left.shape[0],1)), \n",
    "               np.zeros((x_red_right.shape[0], 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAdUAAAA4CAYAAACrFGIfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAABb5JREFUeJzt3F+o5HUdxvHncU0UJEWEslxwLxT8g/+QRcqLETEWERcv\n",
       "JANJ7bZoCal090IhQlFIofDKCiJMIUVcNHRRh4JgodjV1V1ZvahWIUUMSUTS9ulifspxOzNzdubz\n",
       "2++Z8f2C4cyc+f15vuc3Z54zv/OdcRIBAID5Hdc6AAAAy4JSBQCgCKUKAEARShUAgCKUKgAARShV\n",
       "AACKHD/rirZ5Lw4A4HMliactMNNltOps6y7CRdJdc21j3vXn2c64dbrvzzw26a6Sca3cxrTtzbC/\n",
       "VcdXdTwSSRm7rSPvW3l70nrd/cMj111tHUmffv/Ir6ttZ7WM47Ks3N60vNU/u0+Okz59nM6w/8Lj\n",
       "PNN+1rD//3t8fnL7yK+z5Kn6HZ35+Lbb9zEaX6Ytw+lfAACKUKoAABShVMcbtg7Qo2HrAD0btg7Q\n",
       "s2HrAD0btg7Qs2HrAD0atg7QGqU6RpJh6wx9WeaxSYxv0TG+xbXMY1srShUAgCKUKgAARShVAACK\n",
       "UKoAABShVAEAKEKpAgBQhFIFAKAIpQoAQBFKFQCAIpQqAABFKFUAAIpQqgAAFKFUAQAoQqkCAFCE\n",
       "UgUAoAilCgBAEUoVAIAilCoAAEUo1TFsD1pn6Msyj01ifIuO8S2uZR7bWlGq4w1aB+jRoHWAng1a\n",
       "B+jZoHWAng1aB+jZoHWAHg1aB2iNUgUAoAilCgBAESeZbUV7thUBAFhQSTzp/plLFQAAfBanfwEA\n",
       "KEKpAgBQZO5StX2b7cO2T6sItF7Y/ontF23vtf2c7Y2tM1WyfZ/tA90YH7d9SutMlWzfYPsV2/+1\n",
       "fWnrPBVsb7H9qu3XbP+4dZ5qtn9l+y3b+1pnqWZ7o+0Xusfky7a/3zpTJdsn2t7dPV/ut31360zV\n",
       "bG+wvcf2zknLzVWqXdFcLenv82xnnbo3yUVJLpb0hKQ7Wwcq9qyk85NcJOmgpDsa56m2T9L1kv7Y\n",
       "OkgF2xsk/ULSFknnSfqW7XPbpir3a43Gt4w+kvSDJOdLulzSd5fp+CX5UNKV3fPlhZKutH1F41jV\n",
       "tknaL2niRKR5X6n+TNKP5tzGupTk3ytunizpnVZZ+pBkV5LD3c3dks5smadakleTHGydo9BmSa8n\n",
       "+VuSjyQ9Imlr40ylkvxJ0r9a5+hDkn8m2dtdf1/SAUlfaZuqVpIPuqsnSNog6d2GcUrZPlPSNZIe\n",
       "kjRx9u/MpWp7q6Q3krw06zbWO9s/tf0PSTdLuqd1nh59R9LTrUNgoq9KOrTi9hvd97BgbJ8l6RKN\n",
       "/phdGraPs71X0luSXkiyv3WmQvdL+qGkw9MWPH7SnbZ3SfryKnft0Oh04TdWLn4UAdeFCePbnmRn\n",
       "kh2Sdti+XaMf6q3HNOCcpo2vW2aHpP8kefiYhiuwlvEtEd77tgRsnyzp95K2da9Yl0Z35uvibn7G\n",
       "M7YHSYaNY83N9rWS3k6yZy2fbTyxVJNcPWYnF0jaJOlF29Lo1OFfbW9O8vZRp25k3PhW8bAW8JXc\n",
       "tPHZvkWjUxpXHZNAxY7i+C2DNyWtnCy3UaNXq1gQtr8g6TFJv03yROs8fUnynu2nJF0madg4ToWv\n",
       "SbrO9jWSTpT0Rdu/SfLt1Rae6fRvkpeTfCnJpiSbNPrlvnSRCnUa22evuLlV0p5WWfpge4tGpzO2\n",
       "dpMMltnCnUVZxV8knW37LNsnSPqmpCcbZ8IaefTq45eS9id5oHWearZPt31qd/0kjSawLsVzZpLt\n",
       "STZ2XXejpOfHFapU9z7VZTw1dbftfd3/CAaSbmucp9rPNZqAtaubJv5g60CVbF9v+5BGMy2fsv2H\n",
       "1pnmkeRjSd+T9IxGMxAfTXKgbapatn8n6c+SzrF9yPZC/btliq9LukmjWbF7ussyzXQ+Q9Lz3fPl\n",
       "bkk7kzzXOFNfJvYdH1MIAEARPlEJAIAilCoAAEUoVQAAilCqAAAUoVQBAChCqQIAUIRSBQCgCKUK\n",
       "AECR/wEmmo+AwGnp6wAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106719d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot samples from both classes as lines on a 1D space\n",
    "plt.figure(figsize=(8,0.5))\n",
    "plt.xlim(-4,4)\n",
    "plt.ylim(-1,1)\n",
    "# Plot samples\n",
    "plt.plot(x_blue, np.zeros_like(x_blue), 'b|', ms = 30) \n",
    "plt.plot(x_red_left, np.zeros_like(x_red_left), 'r|', ms = 30) \n",
    "plt.plot(x_red_right, np.zeros_like(x_red_right), 'r|', ms = 30) \n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization by backpropagation\n",
    "\n",
    "We will train this model by using the [backpropagation](http://en.wikipedia.org/wiki/Backpropagation) algorithm that is typically used to train neural networks. Each step in the backpropagation algorithm consists of two steps:\n",
    "\n",
    "1. A forward propagation step to compute the output of the network.\n",
    "2. A backward propagation step in which the error at the end of the network is propagated backwards through all the neurons, while updating their parameters.\n",
    "\n",
    "### 1. Forward step\n",
    "\n",
    "During the forward step the input will be propagated layer by layer through the network to compute the final output of the network.\n",
    "\n",
    "The $n$ input samples with $1$ variable each are given as a $n \\times 1$ matrix $X = [x_1 \\ldots x_n]^T$. These inputs are projected onto the 2 dimension of the hidden layer $H$ by according to: \n",
    "\n",
    "$$H = \\sigma(X * W_h + b_h) = \\frac{1}{1+e^{-(X * W_h + b_h)}} $$\n",
    "\n",
    "Where $W_h = [w_{h1}, w{h2}]$ the weight matrix, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the logistic function\n",
    "def logistic(z): return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Weights and biases\n",
    "wh = np.asmatrix([[1, 1]])\n",
    "bh = np.asmatrix([[0, 0]])\n",
    "wo = np.asmatrix([[1], [1]])\n",
    "bo = np.asmatrix([[0]])\n",
    "\n",
    "\n",
    "# Define hidden feedforward\n",
    "def layer_hidden_ff(x, wh, bh):\n",
    "    return logistic(x.dot(wh)+bh)\n",
    "\n",
    "# print layer_hidden_ff(x, wh, bh)\n",
    "\n",
    "# Define output layer feedforward\n",
    "def layer_output_ff(h, wo, bo):\n",
    "    return logistic(h.dot(wo) + bo)\n",
    "\n",
    "# print layer_output_ff(layer_hidden_ff(x, wh, bh), wo, bo)\n",
    "\n",
    "# Define the neural network function\n",
    "def nn(x, wh, bh, wo, bo): \n",
    "    return layer_output_ff(layer_hidden_ff(x, wh, bh), wo, bo)\n",
    "\n",
    "# Define the neural network prediction function that only returns\n",
    "#  1 or 0 depending on the predicted class\n",
    "def nn_predict(x, wh, bh, wo, bo): return np.around(nn(x, wh, bh, wo, bo))\n",
    "\n",
    "# print nn(x, wh, bh, wo, bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.8232337859\n",
      "[[ 5.52701646  5.52701646]]\n",
      "[[-9.9041896 -9.9041896]]\n"
     ]
    }
   ],
   "source": [
    "# Define the cost function\n",
    "def cost(y, t):\n",
    "    return - np.sum(np.multiply(t, np.log(y)) + np.multiply((1-t), np.log(1-y)))\n",
    "\n",
    "y = nn(x, wh, bh, wo, bo)\n",
    "print cost(y, t)\n",
    "\n",
    "h = layer_hidden_ff(x, wh, bh)\n",
    "\n",
    "# print layer_output_ff(h, wo, bo)\n",
    "# print t\n",
    "# print h\n",
    "\n",
    "# define the gradient function for the output layer\n",
    "def gradient_output(h, wo, bo, t): \n",
    "    return (layer_output_ff(h, wo, bo) - t).T * h\n",
    "\n",
    "go = gradient_output(h, wo, bo, t)\n",
    "print go\n",
    "\n",
    "def gradient_input(x, wh, bh, error_gradient):\n",
    "    return np.sum(x * error_gradient, axis=0)\n",
    "\n",
    "print gradient_input(x, wh, bh, go)\n",
    "\n",
    "# define the update function delta w which returns the \n",
    "#  delta w for each weight in a vector\n",
    "def delta_w(w_k, x, t, learning_rate):\n",
    "    return learning_rate * gradient(w_k, x, t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
