{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A Simple Neural network\n",
    "## Part 2: Logistic regression (classification)\n",
    "\n",
    "This tutorial is part 2 of the [previous tutorial on neural networks](http://peterroelants.github.io/posts/2015/05/18/Simple_neural_network_part01/). While the previous tutorial described a very simple one-input-one-output linear regression model, this tutorial will describe a 2-class classification neural network with two input dimensions. This model is known in statistics as the [logistic regression](http://en.wikipedia.org/wiki/Logistic_regression) model.\n",
    "\n",
    "![Image of the logistic model](https://dl.dropboxusercontent.com/u/8938051/Blog_images/SimpleANN02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import numpy as np # Matrix and vector computation package\n",
    "np.seterr(all='ignore') # ignore numpy warning like multiplication of inf\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "from matplotlib.colors import colorConverter, ListedColormap # some plotting functions\n",
    "# Allow matplotlib to plot inside this notebook\n",
    "%matplotlib inline\n",
    "# Set the seed of the numpy random number generator so that the tutorial is reproducable\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the class distributions\n",
    "\n",
    "In this example the target classes $t$ will be generated from 2 class distributions: blue ($t=1$) and red ($t=0$). Samples from both classes are sampled from their respective distributions. These samples are plotted in the figure below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define and generate the samples\n",
    "nb_of_samples_per_class = 20  # The number of sample in each class\n",
    "red_mean = [-1,0]  # The mean of the red class\n",
    "blue_mean = [1,0]  # The mean of the blue class\n",
    "std_dev = 1.2  # standard deviation of both classes\n",
    "# Generate samples from both classes\n",
    "x_red = np.random.randn(nb_of_samples_per_class, 2) * std_dev + red_mean\n",
    "x_blue = np.random.randn(nb_of_samples_per_class, 2) * std_dev + blue_mean\n",
    "\n",
    "# Merge samples in set of input variables x, and corresponding set of\n",
    "# output variables t\n",
    "x = np.vstack((x_red, x_blue))\n",
    "t = np.vstack((np.zeros((nb_of_samples_per_class,1)), np.ones((nb_of_samples_per_class,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot both classes on the x1, x2 plane\n",
    "plt.plot(x_red[:,0], x_red[:,1], 'ro', label='class red')\n",
    "plt.plot(x_blue[:,0], x_blue[:,1], 'bo', label='class blue')\n",
    "plt.grid()\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.axis([-4, 4, -4, 4])\n",
    "plt.title('red vs blue classes in the input space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic function\n",
    "\n",
    "The goal is to predict the target class $t$ from the input values $x$. The network is defined as having an input $x = [x_1, x_2]$ which gets transformed by the weights $w = [w_1, w_2]$ to generate the probability that sample $x$ belongs to class $t=1$. This probability $P(t=1| x,w)$ is represented by the output $y$ of the network computed as $y = \\sigma(x * w^T)$. $\\sigma$ is the [logistic function](http://en.wikipedia.org/wiki/Logistic_function) and is defined as:\n",
    "$$ \\sigma(z) = \\frac{1}{1+e^{-z}} $$\n",
    "\n",
    "This logistic function maps the input $z$ to an output between $0$ and $1$ as is illustrated in the figure below.\n",
    "\n",
    "We can write the probabilities that the class is $t=1$ or $t=0$ given input $x$ as:\n",
    "\n",
    "$$ P(t=1| x) = \\sigma(x * w^T) = \\frac{1}{1+e^{-x * w^T}} $$\n",
    "$$ P(t=0| x) = 1 - \\sigma(x * w^T) = \\frac{e^{-x * w^T}}{1+e^{-x * w^T}} $$\n",
    "\n",
    "Note that the logistic function is derived from the log [odds ratio](http://www.ats.ucla.edu/stat/mult_pkg/faq/general/odds_ratio.htm) of $P(t=1|x)$ over $P(t=0|x)$.\n",
    "\n",
    "$$\\begin{split}\n",
    "log \\frac{P(t=1|x)}{P(t=0|x)} & = log \\frac{\\frac{1}{1+e^{-x * w^T}}}{\\frac{e^{-x * w^T}}{1+e^{-x * w^T}}} = log \\frac{1}{e^{-x * w^T}} \\\\\n",
    "& = log(1) - log(e^{-x * w^T}) = x * w^T\n",
    "\\end{split}$$\n",
    "\n",
    "This means that the logg odds ratio $log(P(t=1|x)/P(t=0|x))$ changes linearly with the parameters $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the logistic function\n",
    "def logistic(z): return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the logistic function\n",
    "z = np.linspace(-6,6,100)\n",
    "plt.plot(z, logistic(z), 'b-')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\sigma(z)$')\n",
    "plt.title('logistic function')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the cost function\n",
    "\n",
    "As written before the output of the model $y = \\sigma(x * w^T)$ can be interpreted as a probability $y$ that sample $x$ belongs to one class $(t=1)$, or probability $1-y$ that $x$ belongs to the other class $(t=0)$ in a two class classification problem. We note this down as: $P(t=1| x; w) = \\sigma(x * w^T) = y$.\n",
    "\n",
    "This model will be optimized by maximizing the [likelihood](http://en.wikipedia.org/wiki/Likelihood_function) that a given set of parameters $w$ can predict the correct class given an input set $x$ of size $n$, and corresponding labels $t$:\n",
    "\n",
    "$$\\underset{w}{\\text{argmax}}\\; \\mathcal{L}(w|t,x) = \\underset{w}{\\text{argmax}} \\prod_{i=1}^{n} \\mathcal{L}(w|t_i,x_i)$$\n",
    "\n",
    "We can rewrite the likelihood $\\mathcal{L}(w|t,x)$ as the [joint probability](http://en.wikipedia.org/wiki/Joint_probability_distribution) of generating $t$ and $x$ given the parameters $w$: $P(t,x|w)$. Since $P(A,B) = P(A|B)*P(B)$ this can be written as:\n",
    "\n",
    "$$P(t,x|w) = P(t|x;w)P(x|w)$$\n",
    "\n",
    "Since we are not interested in the probability of $x$, and $x$ is independent of $w$ we can reduce this to: $\\mathcal{L}(w|t,x) = P(t|x;w) = \\prod_{i=1}^{n} P(t_i|x_i;w)$. \n",
    "Since $t_i$ is a [Bernoulli variable](http://en.wikipedia.org/wiki/Bernoulli_distribution) we can rewrite this as: \n",
    "\n",
    "$$\\begin{split}\n",
    "P(t|x;w) & = \\prod_{i=1}^{n} P(t_i=1|x_i;w)^{t_i} * (1 - P(t_i=1|x_i;w))^{1-t_i} \\\\\n",
    "& = \\prod_{i=1}^{n} y_i^{t_i} * (1 - y_i)^{1-t_i} \\end{split}$$\n",
    "\n",
    "Since the logartimic function is a monotone increasing function we can optimize the log-likelihood function $\\underset{w}{\\text{argmax}}\\; log \\mathcal{L}(w|t,x)$. This maximum will be the same as the maximum from the regular likelihood function. The log-likelihood function can be written as:\n",
    "\n",
    "$$\\begin{split} log \\mathcal{L}(w|t,x) & = log \\prod_{i=1}^{n} y_i^{t_i} * (1 - y_i)^{1-t_i} \\\\\n",
    "& = \\sum_{i=1}^{n} t_i log(y_i) + (1-t_i) log(1 - y_i)\n",
    "\\end{split}$$\n",
    "\n",
    "Minimizing the negative of this function (minimizing the negative log likelihood) corresponds to maximizing the likelihood. This error function $\\xi(t,y)$ is typically known as the [cross-entropy error function](http://en.wikipedia.org/wiki/Cross_entropy) (also known as log-loss):\n",
    "\n",
    "$$\\begin{split}\n",
    "\\xi(t,y) & = - log \\mathcal{L}(w|t,x) \\\\\n",
    "& = - \\sum_{i=1}^{n} \\left[ t_i log(y_i) + (1-t_i)log(1-y_i) \\right] \\\\\n",
    "& = - \\sum_{i=1}^{n} \\left[ t_i log(\\sigma((x_i * w) + b)) + (1-t_i)log(1-\\sigma((x_i * w) + b)) \\right]\n",
    "\\end{split}$$\n",
    "\n",
    "This function looks complicated but besided the previous derivation there are a couple of intuitions why this function is used as a cost function for logistic regression. First of all it can be rewritten as:\n",
    "\n",
    "$$ \\xi(t_i,y_i) = \n",
    "   \\begin{cases}\n",
    "   -log(y_i) & \\text{if } t_i = 1 \\\\\n",
    "   -log(1-y_i) & \\text{if } t_i = 0\n",
    "  \\end{cases}$$\n",
    "  \n",
    "Which in the case of $t_i=1$ is $0$ if $y_i=1$ $(-log(1)=0)$ and goes to infinity as $y_i \\rightarrow 0$ $(\\underset{y \\rightarrow 0}{\\text{lim}}  -log(y) = +\\infty)$. The reverse effect is happening if $t_i=0$.  \n",
    "So what we end up with is a cost function that is $0$ if the probability to predict the correct class is $1$, and goes to infinity as the probability to predict the correct class goes to $0$.\n",
    "\n",
    "Notice that the cost function $\\xi(t_i,y_i)$ is equal to the negative [log probability](http://en.wikipedia.org/wiki/Log_probability) that $x_i$ is classified as its correct class:  \n",
    "$-log(P(t_i=1| x_i,w,b)) = -log(y_i)$,  \n",
    "$-log(P(t_i=0| x_i,w,b)) =$ $-log(1-y_i)$.\n",
    "\n",
    "By minimizing the negative log probability we will maximize the log probability.\n",
    "\n",
    "Note that since $t_i$ can only be $0$ or $1$, we can write $\\xi(t_i,y_i)$ as:\n",
    "$$ \\xi(t_i,y_i) = -t_i log(y_i) - (1-t_i)log(1-y_i) $$\n",
    "\n",
    "Which will give $\\xi(t,y) = - \\sum_{i=1}^{n} \\left[ t_i log(y_i) + (1-t_i)log(1-y_i) \\right]$ if we sum over all $n$ samples.\n",
    "\n",
    "\n",
    "\n",
    "Another reason to use the cross-entropy function is that in simple logistic regression this results in a [convex](http://en.wikipedia.org/wiki/Convex_function) cost function, of which the global minimum will be easy to find. Note that this is not necessaraly the case anymore in multilayer neural networks. The plane of the cost function resulting from the samples is shown in the figure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the neural network function y = 1 / (1 + numpy.exp(-x*w))\n",
    "def nn(x, w): return logistic(x.dot(w.T))\n",
    "\n",
    "# Define the neural network prediction function that only returns\n",
    "#  1 or 0 depending on the predicted class\n",
    "def nn_predict(x,w): return np.around(nn(x,w))\n",
    "    \n",
    "# Define the cost function\n",
    "def cost(y, t):\n",
    "    return - np.sum(np.multiply(t, np.log(y)) + np.multiply((1-t), np.log(1-y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the cost in function of the weights\n",
    "# Define a vector of weights for which we want to plot the cost\n",
    "nb_of_ws = 100 # compute the cost nb_of_ws times in each dimension\n",
    "ws1 = np.linspace(-5, 5, num=nb_of_ws) # weight 1\n",
    "ws2 = np.linspace(-5, 5, num=nb_of_ws) # weight 2\n",
    "ws_x, ws_y = np.meshgrid(ws1, ws2) # generate grid\n",
    "cost_ws = np.zeros((nb_of_ws, nb_of_ws)) # initialize cost matrix\n",
    "# Fill the cost matrix for each combination of weights\n",
    "for i in xrange(nb_of_ws):\n",
    "    for j in xrange(nb_of_ws):\n",
    "        cost_ws[i,j] = cost(nn(x, np.asmatrix([ws_x[i,j], ws_y[i,j]])) , t)\n",
    "# Plot the cost function surface\n",
    "plt.contourf(ws_x, ws_y, cost_ws, 20)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('cost')\n",
    "plt.xlabel('$w_1$')\n",
    "plt.ylabel('$w_2$')\n",
    "plt.title('Cost function surface')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent optimization of the cost function\n",
    "\n",
    "The [gradient descent](http://en.wikipedia.org/wiki/Gradient_descent) algorithm works by taking the [derivative](http://en.wikipedia.org/wiki/Derivative) of the cost function $\\xi$ with respect to the parameters, and updates the parameters in the direction of the negative [gradient](http://en.wikipedia.org/wiki/Gradient).\n",
    "\n",
    "The parameters $w$ are updated by taking steps proportional to the negative of the gradient: $w(k+1) = w(k) - \\Delta w(k+1)$. $\\Delta w$ is defined as: $\\Delta w = \\mu \\frac{\\partial \\xi}{\\partial w}$ with $\\mu$ the learning rate.\n",
    "\n",
    "We will compute ${\\partial \\xi}/{\\partial w}$, as follows:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial w} = \\frac{\\partial z}{\\partial w} \\frac{\\partial y}{\\partial z} \\frac{\\partial \\xi}{\\partial y}$$\n",
    "\n",
    "Where $y = \\sigma(z)$ is the output of the logistic neuron, and $z = x * w^T$ the input to the logistic neuron. \n",
    "\n",
    "* ${\\partial \\xi}/{\\partial y}$ can be calculated as:\n",
    "\n",
    "$$\\begin{split}\n",
    "\\frac{\\partial \\xi}{\\partial y} & = \\frac{\\partial (-t log(y) - (1-t)log(1-y))}{\\partial y} = \\frac{\\partial (-t log(y))}{\\partial y} +  \\frac{\\partial (- (1-t)log(1-y))}{\\partial y} \\\\\n",
    "& = -\\frac{t}{y} + \\frac{1-t}{1-y} = \\frac{y-t}{y(1-y)}\n",
    "\\end{split}$$\n",
    "\n",
    "\n",
    "* ${\\partial y}/{\\partial z}$ can be calculated as:\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial z} = \\frac{\\partial \\sigma(z)}{\\partial z} = \\frac{\\partial \\frac{1}{1+e^{-z}}}{\\partial z} = \\frac{e^{-z}}{(1+e^{-z})^2} = \\frac{1}{1+e^{-z}} \\frac{e^{-z}}{1+e^{-z}}$$\n",
    "\n",
    "And since $1 - \\sigma(z)) = 1 - {1}/(1+e^{-z}) = {e^{-z}}/(1+e^{-z})$ this can be rewritten as:\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial z} = \\frac{1}{1+e^{-z}} \\frac{e^{-z}}{1+e^{-z}} = \\sigma(z) * (1- \\sigma(z)) =  y (1-y)$$\n",
    "\n",
    "* ${\\partial z}/{\\partial w}$ can be calculated as:\n",
    "\n",
    "$$\\frac{\\partial z}{\\partial w} = \\frac{\\partial (x * w)}{\\partial w} = x $$\n",
    "\n",
    "Bringing this together we can write:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial w} = \\frac{\\partial z}{\\partial w} \\frac{\\partial y}{\\partial z} \\frac{\\partial \\xi}{\\partial y} = x * y (1-y) * \\frac{y-t}{y(1-y)} = x * (y-t) $$\n",
    "\n",
    "Notice how this gradient is the same (negating the constant factor) as the gradient of the squared error regression.\n",
    "\n",
    "So the full update function $\\Delta w_j$ for each weight will become\n",
    "\n",
    "$$\\Delta w_j = \\mu * \\frac{\\partial \\xi}{\\partial w_j} = \\mu * x_j * (y-t)$$\n",
    "\n",
    "In the batch processing, we just add up all the gradients for each sample:\n",
    "\n",
    "$$\\Delta w_j = \\mu * \\sum_{i=1}^{n} x_{ij} (y_i - t_i)$$\n",
    "\n",
    "To start out the gradient descent algorithm, you typically start with picking the initial parameters at random and start updating these parameters according to the delta rule with $\\Delta w$ until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the gradient function.\n",
    "def gradient(w, x, t): return (nn(x, w) - t).T * x\n",
    "\n",
    "# define the update function delta w which returns the \n",
    "#  delta w for each weight in a vector\n",
    "def delta_w(w_k, x, t, learning_rate):\n",
    "    return learning_rate * gradient(w_k, x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent updates\n",
    "\n",
    "An example run of gradient descent on the example inputs $x$ and targets $t$ is shown in the figure below. The black dots represent the weight parameter values $w(k)$ at iteration $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the initial weight parameter\n",
    "w = np.asmatrix([-4, -2])\n",
    "# Set the learning rate\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Plot the error surface\n",
    "plt.contourf(ws_x, ws_y, cost_ws, 20, alpha=0.7)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('cost')\n",
    "\n",
    "# Start the gradient descent updates and plot the iterations\n",
    "nb_of_iterations = 3  # number of gradient descent updates\n",
    "for i in xrange(nb_of_iterations):\n",
    "    dw = delta_w(w, x, t, learning_rate)  # get the delta w update\n",
    "    # Plot the weight-cost value and the line that represents the update\n",
    "    plt.plot(w[0,0], w[0,1], 'ko')  # Plot the weight cost value\n",
    "    w_new = w-dw # update the weights\n",
    "    plt.plot([w[0,0], w_new[0,0]], [w[0,1], w_new[0,1]], 'k-')\n",
    "    plt.text(w[0,0]-0.2, w[0,1]+0.4, '$w({})$'.format(i))\n",
    "    w = w_new  # set the weight to the updated weights\n",
    "    \n",
    "# Plot the last weight, axis, and show figure\n",
    "plt.plot(w[0,0], w[0,1], 'ko')\n",
    "plt.text(w[0,0]-0.2, w[0,1]+0.4, '$w({})$'.format(nb_of_iterations))  \n",
    "plt.xlabel('$w_1$')\n",
    "plt.ylabel('$w_2$')\n",
    "plt.title('Gradient descent updates on cost surface')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting decision boundary of running gradient descent on the example inputs $x$ and targets $t$ is shown in the figure below. The background color refers to the classification decision of the trained classifier. Note that since this decision plane is linear that not all examples can be classified correctly. Two blue dots will be misclassified as red, and four red spots will be misclassified as blue.\n",
    "\n",
    "Not that the decision boundary goes through the point $(0,0)$ since we don't have a bias parameter on the logistic output unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the initial weight parameter\n",
    "w = np.asmatrix([-4, -2])\n",
    "# Set the learning rate\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Start performing the gradient descent updates, and print the weights and cost:\n",
    "nb_of_iterations = 10  # number of gradient descent updates\n",
    "for i in xrange(nb_of_iterations):\n",
    "    dw = delta_w(w, x, t, learning_rate)  # get the delta w update\n",
    "    w = w - dw  # update the current weight parameter\n",
    "\n",
    "    \n",
    "# Plot the resulting decision boundary\n",
    "# Generate a grid over the input space to plot the color of the\n",
    "#  classification at that grid point\n",
    "nb_of_xs = 100\n",
    "xs1 = np.linspace(-4, 4, num=nb_of_xs)\n",
    "xs2 = np.linspace(-4, 4, num=nb_of_xs)\n",
    "xx, yy = np.meshgrid(xs1, xs2) # create the grid\n",
    "# Initialize and fill the classification plane\n",
    "classification_plane = np.zeros((nb_of_xs, nb_of_xs))\n",
    "for i in xrange(nb_of_xs):\n",
    "    for j in xrange(nb_of_xs):\n",
    "        classification_plane[i,j] = nn_predict(np.asmatrix([xx[i,j], yy[i,j]]) , w)\n",
    "# Create a color map to show the classification colors of each grid point\n",
    "cmap = ListedColormap([\n",
    "        colorConverter.to_rgba('r', alpha=0.40),\n",
    "        colorConverter.to_rgba('b', alpha=0.40)])\n",
    "\n",
    "# Plot the classification plane with decision boundary and input samples\n",
    "plt.contourf(xx, yy, classification_plane, cmap=cmap)\n",
    "plt.plot(x_red[:,0], x_red[:,1], 'ro', label='target red')\n",
    "plt.plot(x_blue[:,0], x_blue[:,1], 'bo', label='target blue')\n",
    "plt.grid()\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('red vs blue classification boundary')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
